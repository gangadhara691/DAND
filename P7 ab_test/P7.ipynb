{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# A/B Testing\n",
    "\n",
    "## Experiment Objective:\n",
    "> The Hypothesis is by getting to know how many hours a student can be commited to the course can reduce the number of frustrated enrolled students , who eventually will the leave the course due to lack of commitment of time.\n",
    "Without much decrease in number of students to enroll , we can get more focused group of students for better counsiling from udacity coaches and improve student experience to complete the course successfully\n",
    "\n",
    "\n",
    "## Experiment Design \n",
    "### Metric Choice \n",
    "\n",
    ">List which metrics you will use as invariant metrics and evaluation metrics here. (These should \n",
    "be the same metrics you chose in the \"Choosing Invariant Metrics\" and \"Choosing Evaluation \n",
    "Metrics\" quizzes.)\n",
    "For each metric, explain both why you did or did not use it as an invariant metric and why you did \n",
    "or did not use it as an evaluation metric. Also, state what results you will look for in your \n",
    "evaluation metrics in order to launch the experiment.\n",
    ">> #### Invariant Metrics\n",
    ">>|Metric|Explanation|dmin|\n",
    ">>|---------------|-------------|-----|\n",
    ">>|Number Of Cookies |It is a invariant metric since it is assigned before even the experiment is started, not effect by experiment. And it is distributed random and approximately equal among control and experiment groups|3000|\n",
    ">>|Number Of Clicks|It is a invariant metric since click count before even the experiment is started,not effect by experiment|50|\n",
    ">>|Click Through Probability(CTP)| As number of clicks and number of cookies are invariant,where $$Click Through Probability= \\frac{Number Of Clicks}{Number Of Cookies}$$ , Click Through Probability should be invariant|240|\n",
    "\n",
    "\n",
    "\n",
    ">>#### Evaluation Metrics\n",
    ">>|Metric|Explanation|dmin|\n",
    ">>|--------------------|-------------|-----|\n",
    ">>|Gross Conversion(GC)|$$GC=\\frac{no.of user IDs To Enroll In The Free Trial}{no.of Cookies To Click Start Free Trial}$$ Due to the experiment the no.of userID might be reduced keeping no.of click invariant resulting in drop of GC , Hence from GC we get the relative measure of decrease in frustrated students who eventually will leave the course.|0.01|   \n",
    ">>|Net Conversion(NC)|$$NC=\\frac{Number Of User IDs To Make Payment}{Number Of Cookies To Click Start Free Trial}$$, much decrease in numerator might not be seen and no.of clicks is invariant, so a small decrease in NC will be observed.Hence from NC we get the relative measure of students who eventually will complete the course successfully.|0.0075|\n",
    "\n",
    ">>#### Other Relevant Metrics \n",
    ">>|Metric|Explanation|dmin|\n",
    ">>|--------------------|-----------------|-----|\n",
    ">>|Number Of User IDs|Not a invariant metric since control group will have more no.of userIDs than experiment group. It can be a evalution metric but other metrics give a relative measure which are better options|50|\n",
    ">>|Retention (R)|$$R=\\frac{Number Of User IDs To Make Payment}{Number Of User IDs To EnrollInThe Free Trial}=\\frac{Net Conversion(NC)}{Gross Conversion(GC)}$$ It is a Redundant metric, which can be a evalution metric but choosing GC and NC eliminates the need for Retention metric.It can measure whether or not the screener had an effect on the 14-day dropout rate. And the unit of diversion is not same as unit of analysis leading to higher variability.|0.01|\n",
    "\n",
    ">#### Results that conform the launch of experiment:\n",
    ">>|Metric|Explanation|\n",
    ">>|--------------------|-----------------|\n",
    ">>|Gross Conversion|If we observe a practically significant decrease in GC for control compared to experiment group they are conscious about their commitment of time|\n",
    ">>|Net Conversion|We can expect NC to not go below  practical Sigificance boundary maintaining the Net Conversion conforms launch of experiment| \n",
    "\n",
    " \n",
    "### Measuring Standard Deviation \n",
    ">List the standard deviation of each of your evaluation metrics. (These should be the answers \n",
    "from the \"Calculating standard deviation\" quiz.) \n",
    "For each of your evaluation metrics, indicate whether you think the analytic estimate would be \n",
    "comparable to the the empirical variability, or whether you expect them to be different (in which \n",
    "case it might be worth doing an empirical estimate if there is time). Briefly give your reasoning in \n",
    "each case.\n",
    "\n",
    ">|Title|Probability|N|$$  Std Of Error_{40k} = \\sqrt{\\frac{P(1-P)}{N}} $$|$$ Std Of Error_{5k} =Std Of Error_{40k}\\times \\sqrt{\\frac{40000}{5000}}$$|\n",
    "|------|------|------------------|-------------------|-----|\n",
    "|Gross Conversion|0.20625|3200|          0.007152599|0.0202|\n",
    "|Retention|0.53|660|0.01942741|0.0549|\n",
    "|Net Conversion|0.1093125|3200|0.005515979|0.0156|\n",
    "\n",
    ">Unit of diversion is No.of cookies\n",
    ">and both the denominators of GC and NC is No.of cookies, therefore the unit of analysis is equal to unit of diversion ,so its alright to assume that\n",
    "\n",
    ">$$ {\\sigma}^2_{analytical} \\approx {\\sigma}^2 _{emperical}$$\n",
    ">hence we need not do the empirical analysis.\n",
    "\n",
    "\n",
    "### Sizing \n",
    "\n",
    "#### Number of Samples vs. Power \n",
    ">Indicate whether you will use the Bonferroni correction during your analysis phase, and give the \n",
    "number of pageviews you will need to power you experiment appropriately. (These should be the \n",
    "answers from the \"Calculating Number of Pageviews\" quiz.) \n",
    "> ##### Bonferroni correction:\n",
    ">>The Bonferroni correction should not be used as we are using both the test results of evaluation metrics to make the decision.\n",
    ">>The main problem with Bonferroni correction is that often you will be tracking metrics that are correlated and all tend to move at the same time,in that case this method is too conservative.  \n",
    "\n",
    ">Statistical power (1-$\\beta$)= 80%\n",
    "& Significance level ($\\alpha$)= 5%\n",
    "\n",
    ">|Evaluation Metric|Baseline conversion rate|Minimum detectable effect|number of clicks needed per sample for “Start free trial” |Pageviews per sample|Pageviews for total experiment|\n",
    "|---|---|---|---|---|-----|\n",
    "|Gross conversion|20.625%|1%| 25,835  | 322,937.5 ($25,835 \\times \\frac{40000}{3200}$)|645,875(322,937.5 $\\times$ 2)|\n",
    "|Net conversion|10.93125%|0.75%|27,413 | 342,662.5 ($27,413 \\times \\frac{40000}{3200}$)|685,325(342,662.5 $\\times$ 2)|\n",
    "\n",
    ">Larger sample size is 685325 pageviews enough to power the experiment for both metrics. \n",
    " \n",
    "#### Duration vs. Exposure \n",
    ">Indicate what fraction of traffic you would divert to this experiment and, given this, how many \n",
    "days you would need to run the experiment. (These should be the answers from the \"Choosing \n",
    "Duration and Exposure\" quiz.) \n",
    " \n",
    ">Give your reasoning for the fraction you chose to divert. How risky do you think this experiment \n",
    "would be for Udacity? \n",
    " \n",
    "## Experiment Analysis \n",
    "### Sanity Checks \n",
    ">For each of your invariant metrics, give the 95% confidence interval for the value you expect to \n",
    "observe, the actual observed value, and whether the metric passes your sanity check. (These \n",
    "should be the answers from the \"Sanity Checks\" quiz.) \n",
    " \n",
    ">For any sanity check that did not pass, explain your best guess as to what went wrong based on \n",
    "the day-by-day data. ​Do not proceed to the rest of the analysis unless all sanity checks \n",
    "pass. \n",
    " \n",
    "Result Analysis \n",
    "Effect Size Tests \n",
    "For each of your evaluation metrics, give a 95% confidence interval around the difference \n",
    "between the experiment and control groups. Indicate whether each metric is statistically and \n",
    "practically significant. (These should be the answers from the \"Effect Size Tests\" quiz.) \n",
    " \n",
    "Sign Tests \n",
    "For each of your evaluation metrics, do a sign test using the day-by-day data, and report the \n",
    "p-value of the sign test and whether the result is statistically significant. (These should be the \n",
    "answers from the \"Sign Tests\" quiz.) \n",
    " \n",
    "Summary \n",
    "State whether you used the Bonferroni correction, and explain why or why not. If there are any \n",
    "discrepancies between the effect size hypothesis tests and the sign tests, describe the \n",
    "discrepancy and why you think it arose. \n",
    " \n",
    "Recommendation \n",
    "Make a recommendation and briefly describe your reasoning. \n",
    " \n",
    "Follow-Up Experiment \n",
    "Give a high-level description of the follow up experiment you would run, what your hypothesis \n",
    "would be, what metrics you would want to measure, what your unit of diversion would be, and \n",
    "your reasoning for these choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
