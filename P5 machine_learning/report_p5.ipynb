{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Q1\n",
    " ### Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Introduction to Enron Dataset\n",
    ">Enron was one of the largest companies in the United States resulting into bankruptcy due to corporate fraud  which is one of the largest bankruptcies in U.S. History.In the resulting Federal investigation, there was a significant amount of typically confidential information entered into public record, including tens of thousands of emails and detailed financial data for top executives.\n",
    "\n",
    ">The main goal is identifying person of interests (POI's) using supervised machine learning algorithms for prediction.This model will classify weather the individual is a POI or notPOI by  using rest of the features available and various machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments',\n",
    "'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income',\n",
    "'total_stock_value', 'expenses', 'exercised_stock_options', 'other',\n",
    "'long_term_incentive', 'restricted_stock', 'director_fees']#(all units are in US dollars)\n",
    "\n",
    "email_features = ['to_messages', 'from_poi_to_this_person', 'email_address',\n",
    "'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "#(units are generally number of emails messages;\n",
    "#notable exception is ‘email_address’, which is a text string)\n",
    "\n",
    "poi_label = ['poi']# (boolean, represented as integer)\n",
    "\n",
    "\n",
    "features_list = poi_label + financial_features + email_features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total poi in dataset: 18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "enron= pd.DataFrame.from_dict(data_dict, orient = 'index')\n",
    "print\"total poi in dataset:\", sum(enron['poi']==1)\n",
    "\n",
    "#enron.describe()\n",
    "#We can see all the null values for each index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "salary                       95 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "other                        93 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "poi                          146 non-null bool\n",
      "director_fees                17 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "email_address                111 non-null object\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 24.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>1.250000e+02</td>\n",
       "      <td>1.020000e+02</td>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.260000e+02</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.621943e+05</td>\n",
       "      <td>2073.860465</td>\n",
       "      <td>1.642674e+06</td>\n",
       "      <td>5.081526e+06</td>\n",
       "      <td>5.987054e+06</td>\n",
       "      <td>2.374235e+06</td>\n",
       "      <td>2.321741e+06</td>\n",
       "      <td>1176.465116</td>\n",
       "      <td>1.664106e+05</td>\n",
       "      <td>6.773957e+06</td>\n",
       "      <td>1.087289e+05</td>\n",
       "      <td>4.196250e+07</td>\n",
       "      <td>608.790698</td>\n",
       "      <td>9.190650e+05</td>\n",
       "      <td>41.232558</td>\n",
       "      <td>1.668049e+05</td>\n",
       "      <td>-1.140475e+06</td>\n",
       "      <td>1.470361e+06</td>\n",
       "      <td>64.895349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.716369e+06</td>\n",
       "      <td>2582.700981</td>\n",
       "      <td>5.161930e+06</td>\n",
       "      <td>2.906172e+07</td>\n",
       "      <td>3.106201e+07</td>\n",
       "      <td>1.071333e+07</td>\n",
       "      <td>1.251828e+07</td>\n",
       "      <td>1178.317641</td>\n",
       "      <td>4.201494e+06</td>\n",
       "      <td>3.895777e+07</td>\n",
       "      <td>5.335348e+05</td>\n",
       "      <td>4.708321e+07</td>\n",
       "      <td>1841.033949</td>\n",
       "      <td>4.589253e+06</td>\n",
       "      <td>100.073111</td>\n",
       "      <td>3.198914e+05</td>\n",
       "      <td>4.025406e+06</td>\n",
       "      <td>5.942759e+06</td>\n",
       "      <td>86.979244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>6.922300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.118160e+05</td>\n",
       "      <td>541.250000</td>\n",
       "      <td>8.157300e+04</td>\n",
       "      <td>3.944750e+05</td>\n",
       "      <td>5.278862e+05</td>\n",
       "      <td>4.312500e+05</td>\n",
       "      <td>2.540180e+05</td>\n",
       "      <td>249.750000</td>\n",
       "      <td>-3.896218e+05</td>\n",
       "      <td>4.945102e+05</td>\n",
       "      <td>2.261400e+04</td>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>1.215000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.878400e+04</td>\n",
       "      <td>-6.948620e+05</td>\n",
       "      <td>2.812500e+05</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.599960e+05</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>2.274490e+05</td>\n",
       "      <td>1.101393e+06</td>\n",
       "      <td>1.310814e+06</td>\n",
       "      <td>7.693750e+05</td>\n",
       "      <td>4.517400e+05</td>\n",
       "      <td>740.500000</td>\n",
       "      <td>-1.469750e+05</td>\n",
       "      <td>1.102872e+06</td>\n",
       "      <td>4.695000e+04</td>\n",
       "      <td>4.176250e+07</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.238200e+04</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.085790e+05</td>\n",
       "      <td>-1.597920e+05</td>\n",
       "      <td>4.420350e+05</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.121170e+05</td>\n",
       "      <td>2634.750000</td>\n",
       "      <td>1.002672e+06</td>\n",
       "      <td>2.093263e+06</td>\n",
       "      <td>2.547724e+06</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>1.002370e+06</td>\n",
       "      <td>1888.250000</td>\n",
       "      <td>-7.500975e+04</td>\n",
       "      <td>2.949847e+06</td>\n",
       "      <td>7.995250e+04</td>\n",
       "      <td>8.212500e+07</td>\n",
       "      <td>145.500000</td>\n",
       "      <td>3.620960e+05</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>1.137840e+05</td>\n",
       "      <td>-3.834600e+04</td>\n",
       "      <td>9.386720e+05</td>\n",
       "      <td>72.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>4.345095e+08</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>8.392500e+07</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>1.398517e+06</td>\n",
       "      <td>-8.330000e+02</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             salary   to_messages  deferral_payments  total_payments  \\\n",
       "count  9.500000e+01     86.000000       3.900000e+01    1.250000e+02   \n",
       "mean   5.621943e+05   2073.860465       1.642674e+06    5.081526e+06   \n",
       "std    2.716369e+06   2582.700981       5.161930e+06    2.906172e+07   \n",
       "min    4.770000e+02     57.000000      -1.025000e+05    1.480000e+02   \n",
       "25%    2.118160e+05    541.250000       8.157300e+04    3.944750e+05   \n",
       "50%    2.599960e+05   1211.000000       2.274490e+05    1.101393e+06   \n",
       "75%    3.121170e+05   2634.750000       1.002672e+06    2.093263e+06   \n",
       "max    2.670423e+07  15149.000000       3.208340e+07    3.098866e+08   \n",
       "\n",
       "       exercised_stock_options         bonus  restricted_stock  \\\n",
       "count             1.020000e+02  8.200000e+01      1.100000e+02   \n",
       "mean              5.987054e+06  2.374235e+06      2.321741e+06   \n",
       "std               3.106201e+07  1.071333e+07      1.251828e+07   \n",
       "min               3.285000e+03  7.000000e+04     -2.604490e+06   \n",
       "25%               5.278862e+05  4.312500e+05      2.540180e+05   \n",
       "50%               1.310814e+06  7.693750e+05      4.517400e+05   \n",
       "75%               2.547724e+06  1.200000e+06      1.002370e+06   \n",
       "max               3.117640e+08  9.734362e+07      1.303223e+08   \n",
       "\n",
       "       shared_receipt_with_poi  restricted_stock_deferred  total_stock_value  \\\n",
       "count                86.000000               1.800000e+01       1.260000e+02   \n",
       "mean               1176.465116               1.664106e+05       6.773957e+06   \n",
       "std                1178.317641               4.201494e+06       3.895777e+07   \n",
       "min                   2.000000              -7.576788e+06      -4.409300e+04   \n",
       "25%                 249.750000              -3.896218e+05       4.945102e+05   \n",
       "50%                 740.500000              -1.469750e+05       1.102872e+06   \n",
       "75%                1888.250000              -7.500975e+04       2.949847e+06   \n",
       "max                5521.000000               1.545629e+07       4.345095e+08   \n",
       "\n",
       "           expenses  loan_advances  from_messages         other  \\\n",
       "count  9.500000e+01   4.000000e+00      86.000000  9.300000e+01   \n",
       "mean   1.087289e+05   4.196250e+07     608.790698  9.190650e+05   \n",
       "std    5.335348e+05   4.708321e+07    1841.033949  4.589253e+06   \n",
       "min    1.480000e+02   4.000000e+05      12.000000  2.000000e+00   \n",
       "25%    2.261400e+04   1.600000e+06      22.750000  1.215000e+03   \n",
       "50%    4.695000e+04   4.176250e+07      41.000000  5.238200e+04   \n",
       "75%    7.995250e+04   8.212500e+07     145.500000  3.620960e+05   \n",
       "max    5.235198e+06   8.392500e+07   14368.000000  4.266759e+07   \n",
       "\n",
       "       from_this_person_to_poi  director_fees  deferred_income  \\\n",
       "count                86.000000   1.700000e+01     4.900000e+01   \n",
       "mean                 41.232558   1.668049e+05    -1.140475e+06   \n",
       "std                 100.073111   3.198914e+05     4.025406e+06   \n",
       "min                   0.000000   3.285000e+03    -2.799289e+07   \n",
       "25%                   1.000000   9.878400e+04    -6.948620e+05   \n",
       "50%                   8.000000   1.085790e+05    -1.597920e+05   \n",
       "75%                  24.750000   1.137840e+05    -3.834600e+04   \n",
       "max                 609.000000   1.398517e+06    -8.330000e+02   \n",
       "\n",
       "       long_term_incentive  from_poi_to_this_person  \n",
       "count         6.600000e+01                86.000000  \n",
       "mean          1.470361e+06                64.895349  \n",
       "std           5.942759e+06                86.979244  \n",
       "min           6.922300e+04                 0.000000  \n",
       "25%           2.812500e+05                10.000000  \n",
       "50%           4.420350e+05                35.000000  \n",
       "75%           9.386720e+05                72.250000  \n",
       "max           4.852193e+07               528.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron = enron.replace('NaN', np.nan)\n",
    "print(enron.info())\n",
    "enron.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From th above information about dataset we can conlcude that any point with less than 73 non-null  will be having more than 50%\n",
    "of missing data.\n",
    "And the features seem to be in more than 50% null group\n",
    "\n",
    "|Feature|No.of non-null out of 146|\n",
    "|---|---|\n",
    "|deferral_payments        |    39 non-null| \n",
    "|restricted_stock_deferred   | 18 non-null|\n",
    "|loan_advances          |      4 non-null|\n",
    "|director_fees            |    17 non-null |\n",
    "|deferred_income          |    49 non-null |\n",
    "|long_term_incentive      |    66 non-null |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, BELDEN TIMOTHY N to YEAGER F SCOTT\n",
      "Data columns (total 6 columns):\n",
      "loan_advances                1 non-null float64\n",
      "director_fees                0 non-null float64\n",
      "restricted_stock_deferred    0 non-null float64\n",
      "deferral_payments            5 non-null float64\n",
      "deferred_income              11 non-null float64\n",
      "long_term_incentive          12 non-null float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 1008.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "#now checking these features for poi to conclude how much of data is missing for a poi .\n",
    "missing = ['loan_advances', 'director_fees', 'restricted_stock_deferred',\\\n",
    "           'deferral_payments', 'deferred_income', 'long_term_incentive']\n",
    "enron_poi=enron[enron['poi']==1][missing]\n",
    "enron_poi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'salary',\n",
       " 'deferral_payments',\n",
       " 'total_payments',\n",
       " 'bonus',\n",
       " 'deferred_income',\n",
       " 'total_stock_value',\n",
       " 'expenses',\n",
       " 'exercised_stock_options',\n",
       " 'other',\n",
       " 'long_term_incentive',\n",
       " 'restricted_stock',\n",
       " 'to_messages',\n",
       " 'from_poi_to_this_person',\n",
       " 'email_address',\n",
       " 'from_messages',\n",
       " 'from_this_person_to_poi',\n",
       " 'shared_receipt_with_poi']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# its better to remove these with less non null values\n",
    "removing = ['loan_advances', 'director_fees', 'restricted_stock_deferred']\n",
    "for x in removing:\n",
    "    if x in features_list:\n",
    "        features_list.remove(x)\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAESCAYAAAD+GW7gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+JLUEwa+JPXE/wf0wtAGbnKUfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb23ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "#visualising the outlier\n",
    "\n",
    "import matplotlib.pyplot\n",
    "\n",
    "e = enron[(enron.total_payments != np.nan) & (enron.total_stock_value != np.nan)]\n",
    "\n",
    "matplotlib.pyplot.scatter(x=\"total_payments\", y=\"total_stock_value\", data=e)\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"total_payments\")\n",
    "matplotlib.pyplot.ylabel(\"total_stock_value\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TOTAL'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing outlier \n",
    "enron.total_payments.idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#droping total it must be a spreadsheet mistake\n",
    "enron=enron.drop(\"TOTAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAESCAYAAAD+GW7gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc9834a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LAY KENNETH L'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_dict.pop( 'TOTAL', 0 )\n",
    "\n",
    "e = enron[(enron.total_payments != np.nan) & (enron.total_stock_value != np.nan)]\n",
    "\n",
    "matplotlib.pyplot.scatter(x=\"total_payments\", y=\"total_stock_value\", data=e)\n",
    "matplotlib.pyplot.xlabel(\"total_payments\")\n",
    "matplotlib.pyplot.ylabel(\"total_stock_value\")\n",
    "matplotlib.pyplot.show()\n",
    "enron.total_payments.idxmax()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " LAY KENNETH L  is the next outlier but it is a valid point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#After observing insiderpay.pdf file, I got to know it is not a person so we have to remove THE TRAVEL AGENCY IN THE PARK.\n",
    "enron=enron.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'LOCKHART EUGENE E'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron[enron[financial_features].isnull().all(axis=1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There is 1 person without any financial data that will also need to be removed.\n",
    "enron=enron.drop( 'LOCKHART EUGENE E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enron = enron.replace(np.nan, 'NaN') # since to use tester code, i needed to convert back to \"NaN\"\n",
    "data_dict = enron[features_list].to_dict(orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.79780\tPrecision: 0.22512\tRecall: 0.21150\tF1: 0.21810\tF2: 0.21409\n",
      "\tTotal predictions: 15000\tTrue positives:  423\tFalse positives: 1456\tFalse negatives: 1577\tTrue negatives: 11544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tester import test_classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "if \"email_address\" in features_list:\n",
    "    features_list.remove(\"email_address\")\n",
    "    feat=features_list\n",
    "else :\n",
    "    feat=features_list\n",
    "test_classifier(clf, data_dict, feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "\n",
    "### What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding three new features\n",
    "for key, value in my_dataset.items():\n",
    "    if value['from_messages'] == 'NaN' or value['from_this_person_to_poi'] == 'NaN':\n",
    "        value['person_to_poi/total_msgs'] = 0.0\n",
    "    else:\n",
    "        value['person_to_poi/total_msgs'] = value['from_this_person_to_poi'] / (1.0*value['from_messages'])\n",
    "\n",
    "    if value['to_messages'] == 'NaN' or value['from_poi_to_this_person'] == 'NaN':\n",
    "        value['poi_to_person/to_msgs'] = 0.0\n",
    "    else:\n",
    "        value['poi_to_person/to_msgs'] = value['from_poi_to_this_person'] / (1.0*value['to_messages'])\n",
    "    if value['shared_receipt_with_poi'] == 'NaN' or value['from_poi_to_this_person'] == 'NaN' \\\n",
    "        or value['from_this_person_to_poi'] == 'NaN':\n",
    "        value['total_poi_interaction'] = 0.0\n",
    "    else:\n",
    "        value['total_poi_interaction'] = value['shared_receipt_with_poi'] + \\\n",
    "                                      value['from_this_person_to_poi'] + \\\n",
    "                                      value['from_poi_to_this_person'] \n",
    "features_new_list=features_list+['person_to_poi/total_msgs','poi_to_person/to_msgs','total_poi_interaction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I tried to make features of ratios : \n",
    "$$\\frac{from-this-person-to-poi}{from-messages}$$\n",
    "\n",
    "\n",
    "\n",
    "$$\\frac{from-poi-to-this-person}{from-messages}$$\n",
    "\n",
    "#### and\n",
    "\n",
    "$$total-poi-interaction = (shared-receipt-with-poi) + (from-this-person-to-poi) + (from-poi-to-this-person) $$ \n",
    "\n",
    "## These features were selected since , a poi is often tend to be in contact of another poi.Which may lead to higher importance of features.And the total  interaction with poi gives a higher chance of finding a poi \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:10: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>24.815080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>24.182899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>20.792252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>18.289684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_to_poi/total_msgs</th>\n",
       "      <td>16.409713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>11.458477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>9.922186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>9.212811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>8.772778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_poi_interaction</th>\n",
       "      <td>8.616648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>8.589421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>6.094173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>5.243450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>4.187478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi_to_person/to_msgs</th>\n",
       "      <td>3.128092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>2.382612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>1.646341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>0.224611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>0.169701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Importances\n",
       "exercised_stock_options     24.815080\n",
       "total_stock_value           24.182899\n",
       "bonus                       20.792252\n",
       "salary                      18.289684\n",
       "person_to_poi/total_msgs    16.409713\n",
       "deferred_income             11.458477\n",
       "long_term_incentive          9.922186\n",
       "restricted_stock             9.212811\n",
       "total_payments               8.772778\n",
       "total_poi_interaction        8.616648\n",
       "shared_receipt_with_poi      8.589421\n",
       "expenses                     6.094173\n",
       "from_poi_to_this_person      5.243450\n",
       "other                        4.187478\n",
       "poi_to_person/to_msgs        3.128092\n",
       "from_this_person_to_poi      2.382612\n",
       "to_messages                  1.646341\n",
       "deferral_payments            0.224611\n",
       "from_messages                0.169701"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selectkbest used to rank the features\n",
    "data = featureFormat(my_dataset, features_new_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "selector = SelectKBest(k='all').fit(features, labels)\n",
    "results = pd.DataFrame(selector.scores_,\n",
    "                          index=features_new_list[1:])\n",
    "results.columns = ['Importances']\n",
    "results = results.sort(['Importances'], ascending=False)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.81827\tPrecision: 0.31231\tRecall: 0.30200\tF1: 0.30707\tF2: 0.30401\n",
      "\tTotal predictions: 15000\tTrue positives:  604\tFalse positives: 1330\tFalse negatives: 1396\tTrue negatives: 11670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tester import test_classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "if \"email_address\" in features_new_list:\n",
    "    features_new_list.remove(\"email_address\")\n",
    "    feat=features_new_list\n",
    "else :\n",
    "    feat=features_list\n",
    "test_classifier(clf, my_dataset, features_new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - We can clearly see that the performance values are increasing which indicates these would be a good predictor \n",
    "#### -  From the above we can observe the ranking of various features, on adding these features their is a certain increase in accuracy, precision and recall\n",
    "\n",
    "#### - SelectKBest was used to rank and select the features .\n",
    "\n",
    "#### - GridSearchCV was used to select the appropriate value of k in SelectKBest to give the maximum F1 score for the classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "**What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines.\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters={}\n",
    "parameters[\"DecisionTreeClassifier\"] = [{'min_samples_split': [2,3], 'criterion': [ 'entropy']}]\n",
    "parameters[\"GaussianNB\"] = [{ 'selection__k':[9,10,11], 'pca__n_components': [2,3,4,5] }]\n",
    "\n",
    "parameters[\"SVC\"]  = [{'selection__k':[11], 'svc__kernel': ['rbf',\"sigmoid\"], 'svc__C': [x/1.0 for x in range(1, 100,10)]\n",
    "                        ,'svc__gamma':[0.1**(x) for x in range(1,9)]}]\n",
    "parameters[\"AdaBoostClassifier\"] = [{ \"base_estimator\":[DecisionTreeClassifier(min_samples_split= 2, criterion= 'entropy')],'learning_rate' : [x/30.0 for x in range(1, 30)],'n_estimators' : range(1,100,20),\\\n",
    "                    'algorithm': ['SAMME','SAMME.R'] }]\n",
    "parameters[\"KNeighborsClassifier\"] = [{'selection__k': [10,11], \"knn__p\":range(3,4),'pca__n_components': [2,3,4,5],\"knn__n_neighbors\": range(1,10), 'knn__weights': ['uniform','distance'] ,'knn__algorithm': ['ball_tree','kd_tree','brute']}]\n",
    "\n",
    "pipe={}\n",
    "pipe[\"DecisionTreeClassifier\"] = DecisionTreeClassifier()\n",
    "pipe[\"GaussianNB\"] = Pipeline([('scaler', MinMaxScaler()),('selection', SelectKBest()),('pca', PCA()),('naive_bayes', GaussianNB())])\n",
    "pipe[\"SVC\"] =Pipeline([('selection', SelectKBest()),('scaler', StandardScaler())\n",
    "                       ,('svc', SVC())])\n",
    "pipe[\"AdaBoostClassifier\"] =  AdaBoostClassifier()\n",
    "pipe[\"KNeighborsClassifier\"] = Pipeline([('selection',SelectKBest()),\n",
    "                                         ('pca', PCA()),('knn', KNeighborsClassifier())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "data = featureFormat(my_dataset, features_new_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.82800\tPrecision: 0.35644\tRecall: 0.36000\tF1: 0.35821\tF2: 0.35928\n",
      "\tTotal predictions: 15000\tTrue positives:  720\tFalse positives: 1300\tFalse negatives: 1280\tTrue negatives: 11700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=DecisionTreeClassifier()\n",
    "clf_name = clf.__class__.__name__\n",
    "grid = GridSearchCV(estimator =pipe[clf_name],param_grid = parameters[clf_name],\\\n",
    "                                cv = StratifiedKFold(labels_train, n_folds = 6, shuffle = True) \\\n",
    "                            ,n_jobs = -1,scoring = 'f1')\n",
    "grid.fit(features_train, labels_train)\n",
    "print clf_name \n",
    "test_classifier(grid.best_estimator_, my_dataset, features_new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Pipeline(steps=[('selection', SelectKBest(k=11, score_func=<function f_classif at 0x000000000C007DD8>)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=21.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\tAccuracy: 0.82247\tPrecision: 0.32263\tRecall: 0.30150\tF1: 0.31171\tF2: 0.30550\n",
      "\tTotal predictions: 15000\tTrue positives:  603\tFalse positives: 1266\tFalse negatives: 1397\tTrue negatives: 11734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=SVC()\n",
    "clf_name = clf.__class__.__name__\n",
    "grid = GridSearchCV(estimator =pipe[clf_name],param_grid = parameters[clf_name],\\\n",
    "                                cv = StratifiedKFold(labels_train, n_folds = 6, shuffle = False) \\\n",
    "                            ,n_jobs = -1,scoring = 'f1')\n",
    "grid.fit(features_train, labels_train)\n",
    "print clf_name \n",
    "test_classifier(grid.best_estimator_, my_dataset, features_new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=0.933333333333, n_estimators=41, random_state=None)\n",
      "\tAccuracy: 0.82853\tPrecision: 0.35925\tRecall: 0.36500\tF1: 0.36210\tF2: 0.36384\n",
      "\tTotal predictions: 15000\tTrue positives:  730\tFalse positives: 1302\tFalse negatives: 1270\tTrue negatives: 11698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=AdaBoostClassifier()\n",
    "clf_name = clf.__class__.__name__\n",
    "grid = GridSearchCV(estimator =pipe[clf_name],param_grid = parameters[clf_name],\\\n",
    "                                cv = StratifiedKFold(labels_train, n_folds = 6, shuffle = False) \\\n",
    "                            ,n_jobs = -1,scoring = 'f1')\n",
    "grid.fit(features_train, labels_train)\n",
    "print clf_name \n",
    "test_classifier(grid.best_estimator_, my_dataset, features_new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "Pipeline(steps=[('selection', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C007DD8>)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('knn', KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=3,\n",
      "           weights='uniform'))])\n",
      "\tAccuracy: 0.87487\tPrecision: 0.55606\tRecall: 0.30500\tF1: 0.39393\tF2: 0.33528\n",
      "\tTotal predictions: 15000\tTrue positives:  610\tFalse positives:  487\tFalse negatives: 1390\tTrue negatives: 12513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=KNeighborsClassifier()\n",
    "clf_name = clf.__class__.__name__\n",
    "grid = GridSearchCV(estimator =pipe[clf_name],param_grid = parameters[clf_name],\\\n",
    "                                cv = StratifiedKFold(labels_train, n_folds = 6, shuffle = False) \\\n",
    "                            ,n_jobs = -1,scoring = 'f1')\n",
    "grid.fit(features_train, labels_train)\n",
    "print clf_name \n",
    "test_classifier(grid.best_estimator_, my_dataset, features_new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selection', SelectKBest(k=10, score_func=<function f_classif at 0x000000000C007DD8>)), ('pca', PCA(copy=True, iterated_power='auto', n_components=4, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('naive_bayes', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.81913\tPrecision: 0.31576\tRecall: 0.30550\tF1: 0.31055\tF2: 0.30750\n",
      "\tTotal predictions: 15000\tTrue positives:  611\tFalse positives: 1324\tFalse negatives: 1389\tTrue negatives: 11676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=GaussianNB()\n",
    "clf_name = clf.__class__.__name__\n",
    "grid = GridSearchCV(estimator =pipe[clf_name],param_grid = parameters[clf_name],\\\n",
    "                                cv = StratifiedKFold(labels_train, n_folds = 6, shuffle = True) \\\n",
    "                            ,n_jobs = -1,scoring = 'f1')\n",
    "grid.fit(features_train, labels_train)\n",
    "print clf_name \n",
    "test_classifier(grid.best_estimator_, my_dataset, features_new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several different classifiers are deployed:\n",
    "\n",
    "- gaussian naive bayes\n",
    "- k-nearest neighbors\n",
    "- support vector machine\n",
    "- gaussianNB\n",
    "- adaboost\n",
    "\n",
    "  There was not much change in accuracy. \n",
    "  Highest accuracy was for Knearest,Highest precision is for Knearest,Highest recall is for decision tree ,I ended up with really high precision scores for k-nearest neighbors. Unfortunately the recall scores for these weren't as high andalmost all were equal.  The F1 score was highest for the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "**What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning a parameter of an algorithm's main focus is to optimize and get the best output.It mainly focuses on balancing the bias variance trade off ,\n",
    "\n",
    "|High bias model:|High variance model:|\n",
    "|------------|-----------|\n",
    "|where it does not have the capacity to learn anything practically and ignores data.| good at recreating data that it has seen before.Where it cannot generalize new data.|\n",
    "\n",
    "\n",
    "We need a low bias and low variance model to get the most optimized output.\n",
    "Not all the parameters need to be tuned , but there might be a chance for underfitting or overfitting the data,for these cases we need to tune certain parameters of a given estimator.\n",
    "\n",
    "Gaussian NB doesnt have any parameters for tuning.\n",
    "Tuning is done by using GridSearchCV ,\n",
    "\n",
    "GridSearchCV basically is a  systematic way of working through various conjuctions of parameter tunes, cross-validating as it goes to determine which tune gives the best performance.\n",
    "\n",
    "For a given Machine learning algorithm ,for high performance there are diiferent tuning parameters ,\n",
    "to find them we use gridsearchCV.\n",
    "If we input few tuning parameter with a list of possible values for each parameter and it makes different combinations. Grid search technique gives parameters that maximize the score,Which leads to Optimization of learning algorithm.\n",
    "\n",
    "The grid search used a stratified k-fold (set to 6) cross validation so that test and train subset were balanced over the target POI class. \n",
    "My goal was to maximize the precision and recall score so i choose scoring parameter as 'f1' to get a optimized model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "**What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The measure of estimating the model's performance on unseen data is called Validation. The major problem with machine learning algorithm is underfitting or overfitting of our data. The most important thing is to  get to know how the model will generalize to unseen data.\n",
    " \n",
    " We split our data into unseen (testing data) and training data to measure the preformance of the model.For example taking k-fold technique in picture \n",
    " \n",
    "k-fold technique:\n",
    "\n",
    ">First we divide our data set into k parts.A single part is selected as test set and rest (k-1) parts are taken as training set.\n",
    "\n",
    ">>We run  Different learning experiments,every part acts as the testing set one time, and rest acts as the training set K-1 times.\n",
    "\n",
    ">>Assume  a1,a2,....ak (a is the data set and divided into k parts).In each k experiments you pick one of the subsets in aloop from a1 to ak  as testing data and rest as training data.\n",
    "\n",
    " >>We take average of the test result performance by  running multiple times(ie,train our machine learing algoritm and test it using our test set).\n",
    "   \n",
    "   >If we observe Kfold is using all the data for testing as well as all the data for training , hence average of these test results gives us an accurate score.\n",
    "   \n",
    ">>In grid search there might be a chance to overfit the validation set since we use it many times to evaluate performance of different points on the grid and choose a point that delivered good performance.\n",
    "\n",
    ">>Without k-fold cross-validation the risk is higher that grid search will select different parameter value combinations that perform very well on a specific train-test split but poorly on some.\n",
    "\n",
    "\n",
    "We used stratified kfold cross validation.This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.  Stratification of folds in a cross-validation ensure that each test and train set have a balanced proportion of the target class.Hence the number of poi to non pois in each fold would be equal,leading to optimized output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "**Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to see the preformance of the decision tree classifier\n",
    "\n",
    " $$ Accuracy= \\frac{True Positives + True Negatives}{Total Predictions }$$\n",
    " \n",
    " $$ Precision= \\frac{True Positives}{True Positives +False Positives}$$\n",
    " \n",
    " $$ Recall= \\frac{True Positives}{True Positives +False Negitives}$$\n",
    " \n",
    "|Context|Accuracy:\t|Precision: |\tRecall:|\n",
    "|--|-----|-----|-----|\n",
    " |After Data exploration|0.79813|   0.22947  |    0.21800|\n",
    "|After feature selection|    0.81767 | 0.31144| 0.30350|\n",
    "|After tuning parameters| 0.828\t |0.35644\t|0.36000|\t\n",
    "\n",
    "\n",
    "\n",
    "The Decision Tree classifier can correctly identify a person as POI or non-POI with a accuracy of 0.83\n",
    "with precision and recall scores of 0.356 and 0.36.With the Precision score being 0.364,model can  identify  35.6% as actual POI and rest 64.4% are not correctly identified by the classifier.Recall score being 0.36 ,If a POI is present in the test set,  36% of the time classifier would be correctly label the POI.\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
